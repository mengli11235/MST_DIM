{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#sys.path.append(\"/Users/evanracah/Dropbox/projects/atari-representation-learning/\")\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from atariari.benchmark.ram_annotations import atari_dict\n",
    "from atariari.benchmark.categorization import summary_key_dict as skd,  unused_keys, detailed_key_dict, all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game(df, game, methods=[\"cpc\",\"st-dim\"], metric_name=\"f1score\"):\n",
    "    #game = \"seaquest\"\n",
    "\n",
    "    gdf = df[df[\"env_name\"]==game]\n",
    "    mdfs = [gdf[(gdf[\"method\"]==method)] for method in methods] \n",
    "\n",
    "    mdf = pd.concat(mdfs,axis=0)\n",
    "    cols = [c for c in mdf.columns if metric_name in c and c.replace(\"_\"+metric_name, \"\") in atari_dict[game].keys()]\n",
    "    col_change_dic = {col:col.split(\"_\"+metric_name)[0] for col in cols}\n",
    "    cols = [\"method\"] +cols \n",
    "\n",
    "    gmdf = mdf[cols]\n",
    "    gmdf = gmdf.rename(columns=col_change_dic)\n",
    "\n",
    "    gmdf = gmdf.round(2)\n",
    "    gmdf = gmdf.set_index(\"method\")\n",
    "    gmdf = gmdf.T\n",
    "    return gmdf\n",
    "\n",
    "\n",
    "\n",
    "def add_bold_max(latex_str, ignore_last_column=True, ignore_first_column=False, margin=0.01):\n",
    "    strs = []\n",
    "    for r in latex_str.split(\"\\\\\\\\\"):\n",
    "        if \".\" in r:\n",
    "            s = r.split(\"&\")\n",
    "            nums = [float(n) for n in s[1:] if \".\" in n or \"NaN\" in  n]\n",
    "            #print(nums)\n",
    "            am_nums = deepcopy(nums)\n",
    "            if ignore_last_column:\n",
    "                am_nums = am_nums[:-1]\n",
    "                \n",
    "            if ignore_first_column:\n",
    "                am_nums = am_nums[1:]\n",
    "  \n",
    "                \n",
    "                \n",
    "            filt_nums = [n if not np.isnan(n) else -1 for n in am_nums ]\n",
    "            amax, maxx = [np.argmax(filt_nums)], np.max(filt_nums)\n",
    "            for i,n in enumerate(filt_nums):\n",
    "                if i == amax[0]:\n",
    "                    continue\n",
    "                if n+margin >= maxx:\n",
    "                    amax.append(i)\n",
    "            for am in amax:\n",
    "                if ignore_first_column:\n",
    "                    am = am+1\n",
    "                nums[am] = \"\\\\textbf{%5.2f} \"%(nums[am])\n",
    "            nums = [\"%5.2f\"%n if not isinstance(n,str) else n for n in nums ]\n",
    "            nr = [s[0]] + nums\n",
    "            nr = \"  &  \".join(nr)\n",
    "        else:\n",
    "            nr = r\n",
    "        strs.append(nr)\n",
    "\n",
    "    final_latex = \"\\\\\\\\\".join(strs)\n",
    "    final_latex = final_latex.replace(\"nan\",\"NaN\")\n",
    "    return final_latex\n",
    "\n",
    "def keep_most_recent(df):\n",
    "    cf =df.reset_index()\n",
    "\n",
    "    cfs = [cf[cf[\"env_name\"]==game] for game in atari_dict.keys()]\n",
    "\n",
    "    cfs =  [cdf[\"timestamp\"].idxmax() for cdf in cfs]\n",
    "\n",
    "    cf = cf.iloc[cfs]\n",
    "    #print(cf[\"env_name\"])\n",
    "    return cf\n",
    "\n",
    "def translate_method_name(method):\n",
    "        if method == \"spatial-appo\":\n",
    "            method = \"jsd-st-dim\"\n",
    "        elif method == \"infonce-stdim\":\n",
    "            method = \"st-dim\"\n",
    "        elif method == \"global-infonce-stdim\":\n",
    "            method = \"global-t-dim\"\n",
    "        elif method == \"naff\":\n",
    "            method = \"pixel-pred\"\n",
    "        elif method == \"majority\":\n",
    "            method = \"maj-clf\"\n",
    "        elif method == \"global-local-infonce-stdim\":\n",
    "            method = \"gl-st-dim\"\n",
    "        return method\n",
    "    \n",
    "\n",
    "def get_main_df(wandb_proj=\"curl-atari/curl-atari-post-neurips-2\", collect_mode=\"random_agent\"):\n",
    "#     if metric == \"f1\":\n",
    "#         metric_name = \"f1score\"\n",
    "#     elif metric == \"acc\":\n",
    "#         metric_name = \"test_acc\"\n",
    "    api = wandb.Api()\n",
    "    \n",
    "    runs = list(api.runs(wandb_proj, \n",
    "                         {\"state\": \"finished\", \n",
    "                          \"config.collect_mode\":collect_mode,\n",
    "                                                    }))\n",
    "\n",
    "    #df = pd.DataFrame()\n",
    "    rd = [run.summary_metrics for run in runs]\n",
    "    df = pd.DataFrame(rd)\n",
    "    df['env_name'] = [run.config['env_name'].split(\"NoFrameskip\")[0].lower() for run in runs]\n",
    "    ms = []\n",
    "    for run in runs:\n",
    "        method = run.config['method']\n",
    "        method = translate_method_name(method)\n",
    "        ms.append(method)\n",
    "    df['method'] = ms\n",
    "    for metric_name in [\"f1_score\", \"test_acc\"]:\n",
    "        metrics = []\n",
    "        for run in runs:\n",
    "            if \"mean_mean_\" + metric_name in  run.summary_metrics:\n",
    "                metrics.append(run.summary_metrics[\"mean_mean_\" + metric_name] )\n",
    "            elif \"mean_\" + metric_name in run.summary_metrics:\n",
    "                metrics.append(run.summary_metrics[\"mean_\" + metric_name])\n",
    "            else:\n",
    "                metrics.append(np.nan)\n",
    "\n",
    "        df[metric_name] = metrics\n",
    "    df[\"timestamp\"] = [run.summary_metrics['_timestamp'] if \"_timestamp\" in run.summary_metrics else 0  for run in runs  ]\n",
    "\n",
    "    if collect_mode == \"random_agent\":\n",
    "        for method in [\"pixel-pred\"]:\n",
    "            cf = df[df[\"method\"]==method]\n",
    "            cf = keep_most_recent(cf)\n",
    "            df = df[df[\"method\"]!=method]\n",
    "            df = pd.concat([df,cf],axis=0,sort=True)\n",
    "    return df\n",
    "\n",
    "def compute_cat_df(df, metric_name=\"f1score\"):\n",
    "    for cat,cat_keys in skd.items():\n",
    "        cols = [c for c in df.columns if c.split(\"_\" + metric_name)[0] in cat_keys]\n",
    "        df[cat] = df[cols].mean(axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    cat_df = df.loc[:,[\"env_name\",\"method\"] + list(skd.keys())]\n",
    "    \n",
    "    cat_df[\"overall\"] = cat_df.loc[:,list(skd.keys())].mean(axis=1)\n",
    "\n",
    "    return cat_df\n",
    "\n",
    "def get_method_df(cat_df,method):\n",
    "    #method = translate_method_name(method)\n",
    "    cat_df = cat_df.loc[:,[\"method\",\"env_name\", \"overall\"]]\n",
    "    final_cols = [\"env_name\", \"overall\"]\n",
    "    mdf = cat_df.loc[cat_df.method==method].loc[:,final_cols].rename(columns={\"overall\":method})\n",
    "    mdf = mdf.set_index(\"env_name\")\n",
    "    return mdf\n",
    "    \n",
    "\n",
    "def cat_avg(df, methods, metric=\"f1\"):\n",
    "    if metric == \"f1\":\n",
    "        metric_name = \"f1score\"\n",
    "    elif metric == \"acc\":\n",
    "        metric_name = \"test_acc\"\n",
    "    cat_df = compute_cat_df(df, metric_name=metric_name)\n",
    "    cdfs = []\n",
    "    for method in methods:\n",
    "        mdf = get_method_df(cat_df,method)\n",
    "#         print(method,len(mdf))\n",
    "        cdfs.append(mdf)\n",
    "\n",
    "    \n",
    "    ldf = pd.concat(cdfs, axis=1,sort=True)\n",
    "    ldf.loc['mean'] = ldf.mean()\n",
    "    ldf=ldf.round(2)\n",
    "    #latex_ldf = ldf.to_latex()\n",
    "    #print(add_bold_max(latex_ldf, ignore_last_column=ignore_last_column))\n",
    "    return ldf\n",
    "\n",
    "def manual_add(raw_df,ldf,method, metric=\"f1\"):\n",
    "    if metric == \"f1\":\n",
    "        metric_name = \"f1score\"\n",
    "    elif metric == \"acc\":\n",
    "        metric_name = \"test_acc\"\n",
    "    #method = translate_method_name(method)\n",
    "    cat_df = compute_cat_df(raw_df,metric_name=metric_name)\n",
    "    mdf = get_method_df(cat_df, method)\n",
    "    mdf = mdf.sort_values(by=\"env_name\")\n",
    "    mdf.loc['mean'] = mdf.mean()\n",
    "    mdf = mdf.round(2)\n",
    "    ldf[method] = mdf[method].values\n",
    "    return ldf\n",
    "\n",
    "def print_latex(ldf,ignore_last_column=True, ignore_first_column=False):\n",
    "    latex_ldf = ldf.to_latex()\n",
    "    print(add_bold_max(latex_ldf, ignore_last_column=ignore_last_column, ignore_first_column=ignore_first_column))\n",
    "\n",
    "def all_cat(df,methods,ignore_last_column=True, metric=\"f1\"):\n",
    "    if metric == \"f1\":\n",
    "        metric_name = \"f1score\"\n",
    "    elif metric == \"acc\":\n",
    "        metric_name = \"test_acc\"\n",
    "    cat_df = compute_cat_df(df, metric_name=metric_name)\n",
    "    cw_df = pd.DataFrame()\n",
    "\n",
    "    for method in methods:\n",
    "        mdf = cat_df[cat_df[\"method\"]==method]\n",
    "        mdf = mdf[list(skd.keys())]\n",
    "        r = mdf.mean(axis=0)\n",
    "        cw_df[method]  =r\n",
    "\n",
    "    cw_df = cw_df.T\n",
    "    cw_df = cw_df.rename(columns={\"small_object_localization\": \"Small Loc.\",\"agent_localization\":\"Agent Loc.\",\"other_localization\": \"Other Loc.\", \"score_clock_lives_display\": \"Score/Clock/Lives/Display\", \"misc_keys\": \"Misc.\"})\n",
    "    cw_df = cw_df.T\n",
    "    cw_df = cw_df.round(2)\n",
    "    \n",
    "\n",
    " \n",
    "    return cw_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skdd = deepcopy(skd)\n",
    "# skdd[\"overall\"] = all_keys\n",
    "# keys = ['agent_localization',\n",
    "#  'small_object_localization',\n",
    "#  'other_localization',\n",
    "#  'score_clock_lives_display',\n",
    "#  'misc_keys',\n",
    "#  'overall']#list(summary_key_dict.keys())\n",
    "# summary_stats = {env:{sk:0 for sk in keys} for env in atari_dict.keys()}\n",
    "\n",
    "# for env in atari_dict.keys():\n",
    "#     for k in atari_dict[env].keys():\n",
    "#         for sk,v in skdd.items():\n",
    "#             if k in v:\n",
    "#                 summary_stats[env][sk] +=1\n",
    "\n",
    "# print(\" & \".join([\"game\"] + list(keys)))\n",
    "\n",
    "# for env,v in summary_stats.items():\n",
    "#     print( \" & \".join([env] + list(str(v[k]) for k in keys)), \"\\\\\\\\\")\n",
    "# print(\" & \".join([\"total\"] + [str(len(skdd[k])) for k in keys]), \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2 \n",
    "(Average over Categories instead of State Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_df = get_main_df(wandb_proj=\"curl-atari/curl-atari-post-neurips-2\", collect_mode=\"random_agent\")\n",
    "methods = [ \"maj-clf\",\"random-cnn\",\"vae\",\"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"]  #\"pixel-pred\"\n",
    "methods_filt = deepcopy(methods)\n",
    "ldf = cat_avg(df=ra_df,methods=methods_filt, metric=\"f1\")\n",
    "ldf= ldf[methods]\n",
    "ldf[\"vae\"][\"pitfall\"] = ra_df[(ra_df.method == \"vae\") & (ra_df.env_name == \"pitfall\")].across_categories_avg_f1\n",
    "\n",
    "print_latex(ldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3\n",
    "Categorical Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"maj-clf\",\"random-cnn\",\"vae\", \"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"] \n",
    "cw_df = all_cat(ra_df,methods, metric=\"f1\")\n",
    "print_latex(cw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4\n",
    "Incompleteness Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxing_df = get_game(ra_df, \"boxing\",methods=[\"vae\",\"pixel-pred\",\"cpc\",\"global-t-dim\", \"st-dim\"])\n",
    "print_latex(boxing_df,ignore_last_column=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 5\n",
    "No computation needed (text tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_df = get_main_df(collect_mode=\"pretrained_ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_df[(ppo_df.method == \"supervised\") & (ppo_df.env_name == \"tennis\")].mean_mean_f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"maj-clf\",\"random-cnn\",\"vae\", \"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"] \n",
    "methods_filt = deepcopy(methods)\n",
    "ldf = cat_avg(df=ppo_df,methods=methods_filt)\n",
    "ldf= ldf[methods]\n",
    "ldf[\"supervised\"][\"asteroids\"] = ppo_df[(ppo_df.method == \"supervised\") & (ppo_df.env_name == \"asteroids\")].across_categories_avg_f1\n",
    "ldf[\"supervised\"][\"berzerk\"] = ppo_df[(ppo_df.method == \"supervised\") & (ppo_df.env_name == \"berzerk\")].across_categories_avg_f1\n",
    "ldf = ldf.drop(\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add PPO Mean Reward Column on the Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "wandb_proj = \"curl-atari/pretrained-rl-agents-2\"\n",
    "runs = list(api.runs(wandb_proj, \n",
    "                     {\"state\": \"finished\", \n",
    "                                                }))\n",
    "\n",
    "#df = pd.DataFrame()\n",
    "rd = [run.summary_metrics for run in runs]\n",
    "df = pd.DataFrame(rd)\n",
    "\n",
    "df['env_name'] = [run.config['env_name'].split(\"NoFrameskip\")[0].lower() for run in runs]\n",
    "\n",
    "df.columns\n",
    "\n",
    "reward_col = df.set_index(\"env_name\")\n",
    "\n",
    "r_df = reward_col.loc[:,[\"Mean Rewards\"]]\n",
    "\n",
    "cdf = pd.concat((r_df,ldf),axis=1,sort=True)\n",
    "\n",
    "cdf.loc[\"mean\"] = cdf.mean().round(2)\n",
    "cdf.iloc[22,0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf= cdf.rename(columns={\"Mean Rewards\": \"mean agent rewards\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex(cdf, ignore_first_column=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = all_cat(ppo_df,methods)\n",
    "print_latex(cw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 8\n",
    "Ablation Version of Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"static-dim-2\", \"jsd-st-dim\", \"global-t-dim\", \"st-dim\"] \n",
    "adf = cat_avg(ra_df,methods)\n",
    "adf=adf.rename(columns={\"static-dim-2\":\"static-dim\"})\n",
    "print_latex(adf, ignore_last_column=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd, globalt, stdim = [list(adf.values[:,i]) for i in range(3)]\n",
    "ablation_arrays =dict(jsd=jsd, globalt=globalt, stdim=stdim, keys=list(adf.index.values))\n",
    "print(ablation_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 9\n",
    "Ablation Version of Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"static-dim-2\",\"jsd-st-dim\", \"global-t-dim\", \"st-dim\"] \n",
    "acdf = all_cat(ra_df, methods)\n",
    "acdf=acdf.rename(columns={\"static-dim-2\":\"static-dim\"})\n",
    "print_latex(acdf,ignore_last_column=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Table 10 \n",
    "RL Probe With Data from PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_df = get_main_df(collect_mode=\"pretrained_ppo\")\n",
    "methods = [ \"maj-clf\",\"random-cnn\",\"pretrained-rl-agent\"] \n",
    "ldf = cat_avg(df=ppo_df,methods=methods)\n",
    "print_latex(ldf,ignore_last_column=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 11\n",
    "Accuracy Version of Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_df = get_main_df(wandb_proj=\"curl-atari/curl-atari-post-neurips-2\", collect_mode=\"random_agent\")\n",
    "methods = [ \"maj-clf\",\"random-cnn\",\"vae\",\"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"]  #\"pixel-pred\"\n",
    "methods_filt = deepcopy(methods)\n",
    "ldf = cat_avg(df=ra_df,methods=methods_filt, metric=\"acc\")\n",
    "ldf= ldf[methods]\n",
    "ldf[\"vae\"][\"pitfall\"] = ra_df[(ra_df.method == \"vae\") & (ra_df.env_name == \"pitfall\")].across_categories_avg_f1\n",
    "\n",
    "print_latex(ldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 12\n",
    "Accuracy Version of Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"maj-clf\",\"random-cnn\",\"vae\", \"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"] \n",
    "cw_df = all_cat(ra_df,methods, metric=\"acc\")\n",
    "print_latex(cw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables 13-34\n",
    "Fine-Grained Table for Every Game for Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in atari_dict.keys():\n",
    "    metric_name=\"f1score\"\n",
    "    if game == \"pitfall\":\n",
    "        methods=[ \"maj-clf\",\"random-cnn\", \"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"]\n",
    "    else:\n",
    "        methods=[ \"maj-clf\",\"random-cnn\",\"vae\", \"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"]\n",
    "    gmdf = get_game(ra_df,game,\n",
    "                    methods=methods,\n",
    "                   metric_name=metric_name)\n",
    "    gmdf = gmdf.dropna()\n",
    "    if game == \"pitfall\":\n",
    "        vgmdf = get_game(ra_df,game=\"pitfall\",\n",
    "                    methods=[\"vae\"],\n",
    "                   metric_name=\"f1\")\n",
    "        gmdf = pd.concat((vgmdf,gmdf),axis=1)\n",
    "        methods=[ \"maj-clf\",\"random-cnn\",\"vae\", \"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"]\n",
    "        gmdf = gmdf[methods]\n",
    "        \n",
    "\n",
    "    if \"supervised\" in gmdf:\n",
    "        ignore_last_column=True\n",
    "        s = \"|\"\n",
    "    else:\n",
    "        s=\"\"\n",
    "        ignore_last_column=False\n",
    "    print(\"\\\\begin{table*}[ht] \\\\caption{%s fine-grained results. Breakdown of F1 Scores for every state variable in %s  for every method for probes where data was collected by random agent} \\\\label{%s-inc} \\\\vskip 0.15in \\\\begin{center} \\\\begin{small} \\\\begin{sc}\"%(game.capitalize(),game.capitalize(),game.capitalize()))   \n",
    "    print(\" \\\\scalebox{0.9}{ \\\\begin{adjustbox}{center}\")\n",
    "    print(add_bold_max(gmdf.to_latex(),ignore_last_column=ignore_last_column).replace(\"rrr}\", \"rr%sr}\"%s))\n",
    "    print(\"\\\\end{adjustbox}}\")\n",
    "    print(\"\"\"\\\\end{sc}\n",
    "\\\\end{small}\n",
    "\\\\end{center}\n",
    "\\\\vskip -0.1in\n",
    "\\\\end{table*}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables 35-56\n",
    "Fine-Grained Table for Every Game for PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in atari_dict.keys():\n",
    "    metric_name=\"f1score\"\n",
    "    \n",
    "    # must manually add supervised for these ones\n",
    "    if game == \"asteroids\" or game == \"berzerk\":\n",
    "        methods=[ \"maj-clf\",\"random-cnn\",\"vae\", \"pixel-pred\",\"cpc\",\"st-dim\"]\n",
    "    else:\n",
    "        methods=[ \"maj-clf\",\"random-cnn\",\"vae\", \"pixel-pred\",\"cpc\",\"st-dim\", \"supervised\"]\n",
    "    gmdf = get_game(ppo_df,game,\n",
    "                    methods=methods,\n",
    "                   metric_name=metric_name)\n",
    "    gmdf = gmdf.dropna()\n",
    "    if \"supervised\" in gmdf:\n",
    "        ignore_last_column=True\n",
    "        s = \"|\"\n",
    "    else:\n",
    "        s=\"\"\n",
    "        ignore_last_column=False\n",
    "    print(\"\\\\begin{table*}[ht] \\\\caption{%s fine-grained results. Breakdown of F1 Scores for every state variable in %s  for every method for probes where data was collected by a pretrained PPO agent that was trained for 50M frames} \\\\label{%s-inc-ppo} \\\\vskip 0.15in \\\\begin{center} \\\\begin{small} \\\\begin{sc}\"%(game.capitalize(),game.capitalize(),game.capitalize()))   \n",
    "    print(\" \\\\scalebox{0.9}{ \\\\begin{adjustbox}{center}\")\n",
    "    print(add_bold_max(gmdf.to_latex(),ignore_last_column=ignore_last_column).replace(\"rrr}\", \"rr%sr}\"%s))\n",
    "    print(\"\\\\end{adjustbox}}\")\n",
    "    print(\"\"\"\\\\end{sc}\n",
    "\\\\end{small}\n",
    "\\\\end{center}\n",
    "\\\\vskip -0.1in\n",
    "\\\\end{table*}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
